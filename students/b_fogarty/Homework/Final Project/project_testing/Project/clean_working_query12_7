import requests
import json
import csv
import sqlite3 as sql
import pandas as pd
import numpy as np

#class intel_builder(object):

    #dest = dirname(abspath(__file__))

    #def __init__(self, state = 'Massachusetts', input_file = None):

"""
Returns a class for building new database tables with transformed
data of interest
"""
#store parameters

# build API call strings

#def api_scrape(self, input_seq):
"""
Executes get command against CFPB HMDA API, pulling table into memory
(maybe csv?)
"""
def hmda_api(state_abv='WA',limit=0):

lar = requests.get('https://api.consumerfinance.gov/data/hmda/slice/'+
                   'hmda_lar.json?%24select=action_taken_name%2Capplicant_ethnicity_name'+
                   '%2Capplicant_income_000s%2Capplicant_race_name_1%2Capplicant_sex_name'+
                   '%2Cas_of_year%2Ccensus_tract_number%2Cdenial_reason_name_1%2Cdenial_reason_name_2'+
                   '%2Choepa_status_name%2Chud_median_family_income%2Clien_status_name%2C%09loan_amount_000s'+
                   '%2C%09msamd_name%2C%09number_of_1_to_4_family_units%2Cnumber_of_owner_occupied_units%2Cpopulation'+
                   '%2Cpreapproval_name%2Crespondent_id%2Csequence_number%2Cstate_abbr%2Cstate_name'+
                   '%2Ctract_to_msamd_income&%24where=loan_purpose_name%3D%27Home+purchase%27+AND+applicant_income_000s+'+
                   '%3C+100+AND+state_abbr+%3D+%27MA%27+AND+property_type_name+%3D+'+
                   '%27One-to-four+family+dwelling+%28other+than+manufactured+housing'+
                   '%29%27+AND+owner_occupancy_name+%3D+%27Owner-occupied+as+a+principal+dwelling%27+&'+
                   '%24group=&%24orderBy=&%24limit=1000&%24offset=0&%24format=json')

#decoding contents of drequest into pythonic data type, here, a dict
data = lar.json()

#isolating the table of interest, by name of dict I want. Here, a list of 100 dicts
dataset = data['results']
fieldnames = list(dataset[1].keys())
field_count = len(fieldnames)
valuetypes = [type(i) for i in dataset[1].values()]
# getting keys for DDL
all_keys = list()
for i in dataset:
    all_keys.append(i.keys())
unique_keys = set(i for x in all_keys for i in x)

frame = pd.DataFrame(dataset)

#Calculating relative fields
frame['income_to_median'] = (frame['applicant_income_000s']*1000)/frame['hud_median_family_income']
frame['loan_to_income'] = frame['loan_amount_000s']/frame['applicant_income_000s']
#mapping loan decision
decision_map = {
    'Application approved but not accepted': 'Approved',
    'Loan originated': 'Approved',
    'Application withdrawn by applicant': 'Other',
    'Application denied by financial institution': 'Denied',
    'File closed for incompleteness': 'Other',
    'Loan purchased by the institution': 'Approved',
    'Preapproval request denied by financial institution': 'Denied'
}
#rame['simplified_decision'] = frame['action_taken_name'].map(str.lower).map(decision_map)

frame['simplified_decision'] = frame['action_taken_name'].replace(decision_map)

#replacing HOEPA
frame['simplified_hoepa'] = frame['hoepa_status_name'].replace(['HOEPA loan','Not a HOEPA loan'],[1,0])

#denial flags
def denial_flag(row):
    if row['simplified_decision'] == 'Approved':
        return 0
    if row['simplified_decision'] == 'Denied':
        return 1
    if row['simplified_decision'] == 'Other':
        return np.nan

frame['denial_flag'] = frame.apply(lambda row: denial_flag(row), axis = 1)


#binning two fileds into quintiles
#1 income_to_median--ROUNDING!!!!S
#income_med = frame['income_to_median']
#scores = [1,2,3,4,5]
#frame['income_score'] = int(pd.qcut(income_med,5, labels=scores))

#2 loan_to_income
#loan_income = frame['loan_to_income']
#frame['loan_score'] = int(pd.qcut(loan_income,5, labels=scores))

#frame['risk_score'] = (frame['loan_score']*0.4)+(frame['income_score']*0.6)


loan_frame = frame['loan_to_income'].groupby(frame['action_taken_name']).mean()
income_frame = frame['income_to_median'].groupby(frame['action_taken_name']).mean()
census_frame = frame['income_to_median'].groupby(frame['census_tract_number']).mean()

#3
def minority_logic(row):
    if row['applicant_ethnicity_name'] != 'Not Hispanic or Latino':
        return 1
    elif row['applicant_race_name_1'] != 'White':
        return 1
    return 0
frame['minority_flag'] = frame.apply(lambda row: minority_logic(row), axis = 1)


#dataframe grouped on loan risk info
risk = frame.groupby(['state_name','census_tract_number'])
risk_index_report = risk.agg({'income_to_median':'mean',
        'loan_to_income':'mean'})
risk_index_report.sort('income_to_median')


#dataframe grouped on borrower risk info
redline = frame.groupby(['state_name','census_tract_number'])
redlining_report = redline.agg({'minority_flag':'mean',
        'simplified_hoepa':'mean',
        'denial_flag':'mean'})
redlining_report.sort('denial_flag',ascending=False)


    def reports_to_sql(report,alias='full_data'):
        state = (frame['state_name'][0])
        cnx = sql.connect(state + alias +'.sqlite')
        report.to_sql(state+alias,con=cnx,if_exists='replace')
        curs = cnx.cursor
        #cur.execute("SELECT * FROM Massachusetts")
        #df = pd.read_sql_query("SELECT * from Massachusettsredline", sql.connect('Massachusettsredline.sqlite'))
        cnx.commit()

        reports_to_sql(risk_index_report,'_loan_risk')
        reports_to_sql(redlining_report,'_redline')
        redlining_report(frame)


return top 50 census tracts for each risk category














